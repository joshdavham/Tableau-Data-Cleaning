{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3342037e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c8bc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from googletrans import Translator\n",
    "\n",
    "nlp_en = spacy.load(\"en_core_web_sm\")\n",
    "nlp_fr = spacy.load(\"fr_core_news_sm\")\n",
    "nlp_el = spacy.load(\"el_core_news_sm\")\n",
    "nlp_zh = spacy.load(\"zh_core_web_sm\")\n",
    "\n",
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce77efd",
   "metadata": {},
   "source": [
    "# English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88e1d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the text\n",
    "with open('English/Pride and Prejudice.txt','r') as file:###\n",
    "    lines = file.read().splitlines()\n",
    "    \n",
    "#combine the lines into single string\n",
    "text = ' '.join(lines)\n",
    "text = text.lower()\n",
    "\n",
    "#parse the text\n",
    "doc = nlp_en(text)###\n",
    "\n",
    "#tokenize the text into strings excluding punctuation, numbers and whitespace\n",
    "tokens = [str(token) for token in doc if (not token.is_punct) and (not token.like_num) and (not token.is_space)]\n",
    "\n",
    "#count the frequency of the tokens\n",
    "freq = Counter(tokens)\n",
    "\n",
    "#number of unique tokens\n",
    "num_unique = len(freq)\n",
    "\n",
    "#order the tokens by most frequent to least\n",
    "freq = freq.most_common()#freq is now a list\n",
    "\n",
    "#create a dataframe for word, frequency and rank\n",
    "df = pd.DataFrame(freq, columns=['word', 'freq'])\n",
    "df['rank'] = np.array(df.index) + 1\n",
    "\n",
    "#compute relative frequency\n",
    "df['rel freq'] = df['freq'] / num_unique\n",
    "\n",
    "#compute the log rank base 10\n",
    "df['log rank'] = np.log(df['rank']) / np.log(10)\n",
    "#compute the log freq base 10\n",
    "df['log freq'] = np.log(df['freq']) / np.log(10)\n",
    "#compute the log rel freq base 10\n",
    "df['log rel freq'] = np.log(df['rel freq']) / np.log(10)\n",
    "\n",
    "#take just the top 5,000\n",
    "df = df[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78192474",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add english translation\n",
    "df['trans'] = df['word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee069d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e619df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561f9413",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en.to_csv('English/Pride_and_Prejudice_Frequency.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5716c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_en['rank'], df_en['freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caa8e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_en['log rank'], df_en['log freq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc346805",
   "metadata": {},
   "source": [
    "# French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f2308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the text\n",
    "with open('French/Madame Bovary.txt','r') as file:###\n",
    "    lines = file.read().splitlines()\n",
    "    \n",
    "#combine the lines into single string\n",
    "text = ' '.join(lines)\n",
    "text = text.lower()\n",
    "\n",
    "#parse the text\n",
    "doc = nlp_fr(text)###\n",
    "\n",
    "#tokenize the text into strings excluding punctuation, numbers and whitespace\n",
    "tokens = [str(token) for token in doc if (not token.is_punct) and (not token.like_num) and (not token.is_space)]\n",
    "\n",
    "#count the frequency of the tokens\n",
    "freq = Counter(tokens)\n",
    "\n",
    "#number of unique tokens\n",
    "num_unique = len(freq)\n",
    "\n",
    "#order the tokens by most frequent to least\n",
    "freq = freq.most_common()#freq is now a list\n",
    "\n",
    "#create a dataframe for word, frequency and rank\n",
    "df = pd.DataFrame(freq, columns=['word', 'freq'])\n",
    "df['rank'] = np.array(df.index) + 1\n",
    "\n",
    "#compute relative frequency\n",
    "df['rel freq'] = df['freq'] / num_unique\n",
    "\n",
    "#compute the log rank base 10\n",
    "df['log rank'] = np.log(df['rank']) / np.log(10)\n",
    "#compute the log freq base 10\n",
    "df['log freq'] = np.log(df['freq']) / np.log(10)\n",
    "#compute the log rel freq base 10\n",
    "df['log rel freq'] = np.log(df['rel freq']) / np.log(10)\n",
    "\n",
    "#take just the top 5,000\n",
    "df = df[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90539b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fr = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c06037",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34faa5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_fr['rank'], df_fr['freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3c15b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_fr['log rank'], df_fr['log freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36569c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "translations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2a6d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = len(translations)#k is like a checkpoint if program crashes\n",
    "i = len(translations)\n",
    "\n",
    "for word in df_fr[k:]['word']:####\n",
    "    translation = translator.translate(text=word, src='fr', dest='en').text####\n",
    "    \n",
    "    translations.append(translation)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "        \n",
    "    i += 1\n",
    "    \n",
    "df_fr['trans'] = translations####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858eab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8125006",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fr.to_csv('French/Madame_Bovary_Frequency.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36390e8",
   "metadata": {},
   "source": [
    "# Greek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e017de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the text\n",
    "with open('Greek/The Illiad (Ιλιάδα).txt','r') as file:###\n",
    "    lines = file.read().splitlines()\n",
    "    \n",
    "#combine the lines into single string\n",
    "text = ' '.join(lines)\n",
    "text = text.lower()\n",
    "\n",
    "#parse the text\n",
    "doc = nlp_el(text)###\n",
    "\n",
    "#tokenize the text into strings excluding punctuation, numbers and whitespace\n",
    "tokens = [str(token) for token in doc if (not token.is_punct) and (not token.like_num) and (not token.is_space)]\n",
    "\n",
    "#count the frequency of the tokens\n",
    "freq = Counter(tokens)\n",
    "\n",
    "#number of unique tokens\n",
    "num_unique = len(freq)\n",
    "\n",
    "#order the tokens by most frequent to least\n",
    "freq = freq.most_common()#freq is now a list\n",
    "\n",
    "#create a dataframe for word, frequency and rank\n",
    "df = pd.DataFrame(freq, columns=['word', 'freq'])\n",
    "df['rank'] = np.array(df.index) + 1\n",
    "\n",
    "#compute relative frequency\n",
    "df['rel freq'] = df['freq'] / num_unique\n",
    "\n",
    "#compute the log rank base 10\n",
    "df['log rank'] = np.log(df['rank']) / np.log(10)\n",
    "#compute the log freq base 10\n",
    "df['log freq'] = np.log(df['freq']) / np.log(10)\n",
    "#compute the log rel freq base 10\n",
    "df['log rel freq'] = np.log(df['rel freq']) / np.log(10)\n",
    "\n",
    "#take just the top 5,000\n",
    "df = df[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d06aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_el = df####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608bbf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_el.head()####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7240b95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_el['rank'], df_el['freq'])###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04076c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_el['log rank'], df_el['log freq'])###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823b26b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "translations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdbb150",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = len(translations)#k is like a checkpoint if program crashes\n",
    "i = len(translations)\n",
    "\n",
    "for word in df_el[k:]['word']:####\n",
    "    translation = translator.translate(text=word, src='el', dest='en').text####\n",
    "    \n",
    "    translations.append(translation)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "        \n",
    "    i += 1\n",
    "    \n",
    "df_el['trans'] = translations####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6963ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_el.head()####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329f8776",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_el.to_csv('Greek/The_Illiad_Frequency.csv', index=False)###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e41f70",
   "metadata": {},
   "source": [
    "# Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc23b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the text\n",
    "with open('Chinese/Journey to the West (西遊記) First Half.txt','r') as file:###\n",
    "    lines = file.read().splitlines()\n",
    "    \n",
    "#combine the lines into single string\n",
    "text = ' '.join(lines)\n",
    "text = text.lower()\n",
    "\n",
    "#parse the text\n",
    "doc = nlp_zh(text)###\n",
    "\n",
    "#tokenize the text into strings excluding punctuation, numbers and whitespace\n",
    "tokens = [str(token) for token in doc if (not token.is_punct) and (not token.like_num) and (not token.is_space)]\n",
    "\n",
    "#count the frequency of the tokens\n",
    "freq = Counter(tokens)\n",
    "\n",
    "#number of unique tokens\n",
    "num_unique = len(freq)\n",
    "\n",
    "#order the tokens by most frequent to least\n",
    "freq = freq.most_common()#freq is now a list\n",
    "\n",
    "#create a dataframe for word, frequency and rank\n",
    "df = pd.DataFrame(freq, columns=['word', 'freq'])\n",
    "df['rank'] = np.array(df.index) + 1\n",
    "\n",
    "#compute relative frequency\n",
    "df['rel freq'] = df['freq'] / num_unique\n",
    "\n",
    "#compute the log rank base 10\n",
    "df['log rank'] = np.log(df['rank']) / np.log(10)\n",
    "#compute the log freq base 10\n",
    "df['log freq'] = np.log(df['freq']) / np.log(10)\n",
    "#compute the log rel freq base 10\n",
    "df['log rel freq'] = np.log(df['rel freq']) / np.log(10)\n",
    "\n",
    "#take just the top 5,000\n",
    "df = df[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0093cbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zh = df####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970a8cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zh.head()####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b450475",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_zh['rank'], df_zh['freq'])###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7d98fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_zh['log rank'], df_zh['log freq'])###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2a98a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "translations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa073a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = len(translations)#k is like a checkpoint if program crashes\n",
    "i = len(translations)\n",
    "\n",
    "for word in df_zh[k:]['word']:####\n",
    "    translation = translator.translate(text=word, dest='en').text####\n",
    "    \n",
    "    translations.append(translation)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "        \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7872b10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zh['trans'] = translations####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d96b232",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zh.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9236650",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zh.to_csv('Chinese/Journey_to_the_West_Frequency.csv', index=False)###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
