{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4c3878f",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65c4042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e028bc30",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c478dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = ['English', 'French', 'Greek']\n",
    "\n",
    "#load the data into dataframes\n",
    "#for each language\n",
    "token_counts_dfs = {}\n",
    "for language in languages:\n",
    "\n",
    "    token_counts_dfs[language] = pd.read_csv(language + '/' + language.lower() + '_token_counts.csv')\n",
    "    \n",
    "    #only keep every 10th row for processing purposes and graphing\n",
    "    token_counts_dfs[language] = token_counts_dfs[language][token_counts_dfs[language].index % 10 == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9138f9ef",
   "metadata": {},
   "source": [
    "# Translate the Lexemes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da65eba6",
   "metadata": {},
   "source": [
    "## English"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cb2a16",
   "metadata": {},
   "source": [
    "### (add english translation variable to English dataframe just for good measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b517f1ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lexemes_read</th>\n",
       "      <th>unique_lexemes_read</th>\n",
       "      <th>most_recent_unique_lexeme</th>\n",
       "      <th>log_lexemes_read</th>\n",
       "      <th>log_unique_lexemes_read</th>\n",
       "      <th>english_translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>chapter</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>chapter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>man</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>want</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>want</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>25</td>\n",
       "      <td>view</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>view</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>enter</td>\n",
       "      <td>3.713572</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>enter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lexemes_read  unique_lexemes_read most_recent_unique_lexeme  \\\n",
       "0              1                    1                   chapter   \n",
       "10            11                   10                       man   \n",
       "20            21                   17                      want   \n",
       "30            31                   25                      view   \n",
       "40            41                   30                     enter   \n",
       "\n",
       "    log_lexemes_read  log_unique_lexemes_read english_translation  \n",
       "0           0.000000                 0.000000             chapter  \n",
       "10          2.397895                 2.302585                 man  \n",
       "20          3.044522                 2.833213                want  \n",
       "30          3.433987                 3.218876                view  \n",
       "40          3.713572                 3.401197               enter  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_counts_dfs['English']['english_translation'] = token_counts_dfs['English']['most_recent_unique_lexeme']\n",
    "\n",
    "token_counts_dfs['English'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d19ef2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to .csv\n",
    "token_counts_dfs['English'].to_csv('English/english_token_counts.csv', index=False)###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfd33c5",
   "metadata": {},
   "source": [
    "## French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f69e7960",
   "metadata": {},
   "outputs": [],
   "source": [
    "french_lexemes = list(set(token_counts_dfs['French']['most_recent_unique_lexeme']))###\n",
    "fr_en_trans = {}###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0114c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lexemes_read</th>\n",
       "      <th>unique_lexemes_read</th>\n",
       "      <th>most_recent_unique_lexeme</th>\n",
       "      <th>log_lexemes_read</th>\n",
       "      <th>log_unique_lexemes_read</th>\n",
       "      <th>english_translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116760</th>\n",
       "      <td>116761</td>\n",
       "      <td>9048</td>\n",
       "      <td>envoie</td>\n",
       "      <td>11.667884</td>\n",
       "      <td>9.110299</td>\n",
       "      <td>send</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116770</th>\n",
       "      <td>116771</td>\n",
       "      <td>9049</td>\n",
       "      <td>succédé</td>\n",
       "      <td>11.667970</td>\n",
       "      <td>9.110410</td>\n",
       "      <td>succolence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116780</th>\n",
       "      <td>116781</td>\n",
       "      <td>9049</td>\n",
       "      <td>succédé</td>\n",
       "      <td>11.668056</td>\n",
       "      <td>9.110410</td>\n",
       "      <td>succolence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116790</th>\n",
       "      <td>116791</td>\n",
       "      <td>9050</td>\n",
       "      <td>brèche</td>\n",
       "      <td>11.668141</td>\n",
       "      <td>9.110520</td>\n",
       "      <td>breach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116800</th>\n",
       "      <td>116801</td>\n",
       "      <td>9051</td>\n",
       "      <td>protège</td>\n",
       "      <td>11.668227</td>\n",
       "      <td>9.110631</td>\n",
       "      <td>protected</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lexemes_read  unique_lexemes_read most_recent_unique_lexeme  \\\n",
       "116760        116761                 9048                    envoie   \n",
       "116770        116771                 9049                   succédé   \n",
       "116780        116781                 9049                   succédé   \n",
       "116790        116791                 9050                    brèche   \n",
       "116800        116801                 9051                   protège   \n",
       "\n",
       "        log_lexemes_read  log_unique_lexemes_read english_translation  \n",
       "116760         11.667884                 9.110299                send  \n",
       "116770         11.667970                 9.110410          succolence  \n",
       "116780         11.668056                 9.110410          succolence  \n",
       "116790         11.668141                 9.110520              breach  \n",
       "116800         11.668227                 9.110631           protected  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator = Translator()\n",
    "\n",
    "k = len(fr_en_trans)#checkpoint if translator crashes\n",
    "i = len(fr_en_trans)#counter\n",
    "\n",
    "for fr_lex in french_lexemes[k:]:###\n",
    "    \n",
    "    en_trans = translator.translate(text=fr_lex, src='fr', dest='en').text###\n",
    "    \n",
    "    fr_en_trans[fr_lex] = en_trans###\n",
    "    \n",
    "    #counter\n",
    "    if i % 100 == 0:\n",
    "        print(i, 'lexemes translated')\n",
    "    i += 1\n",
    "    \n",
    "token_counts_dfs['French']['english_translation'] = [fr_en_trans[fr_lex] for fr_lex in token_counts_dfs['French']['most_recent_unique_lexeme']]###\n",
    "\n",
    "#save to .csv\n",
    "token_counts_dfs['French'].to_csv('French/french_token_counts.csv', index=False)###\n",
    "\n",
    "token_counts_dfs['French'].tail()###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96da94a",
   "metadata": {},
   "source": [
    "## Greek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c4defbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "greek_lexemes = list(set(token_counts_dfs['Greek']['most_recent_unique_lexeme']))###\n",
    "\n",
    "el_en_trans = {}###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e3499a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lexemes_read</th>\n",
       "      <th>unique_lexemes_read</th>\n",
       "      <th>most_recent_unique_lexeme</th>\n",
       "      <th>log_lexemes_read</th>\n",
       "      <th>log_unique_lexemes_read</th>\n",
       "      <th>english_translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113810</th>\n",
       "      <td>113811</td>\n",
       "      <td>12558</td>\n",
       "      <td>τούσκαψαν</td>\n",
       "      <td>11.642294</td>\n",
       "      <td>9.438113</td>\n",
       "      <td>stuffed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113820</th>\n",
       "      <td>113821</td>\n",
       "      <td>12558</td>\n",
       "      <td>τούσκαψαν</td>\n",
       "      <td>11.642382</td>\n",
       "      <td>9.438113</td>\n",
       "      <td>stuffed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113830</th>\n",
       "      <td>113831</td>\n",
       "      <td>12559</td>\n",
       "      <td>τέλειωσαν</td>\n",
       "      <td>11.642470</td>\n",
       "      <td>9.438193</td>\n",
       "      <td>They ended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113840</th>\n",
       "      <td>113841</td>\n",
       "      <td>12560</td>\n",
       "      <td>ταχτικάς</td>\n",
       "      <td>11.642558</td>\n",
       "      <td>9.438272</td>\n",
       "      <td>tactics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113850</th>\n",
       "      <td>113851</td>\n",
       "      <td>12561</td>\n",
       "      <td>διόσπαρτος</td>\n",
       "      <td>11.642646</td>\n",
       "      <td>9.438352</td>\n",
       "      <td>dilateral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lexemes_read  unique_lexemes_read most_recent_unique_lexeme  \\\n",
       "113810        113811                12558                 τούσκαψαν   \n",
       "113820        113821                12558                 τούσκαψαν   \n",
       "113830        113831                12559                 τέλειωσαν   \n",
       "113840        113841                12560                  ταχτικάς   \n",
       "113850        113851                12561                διόσπαρτος   \n",
       "\n",
       "        log_lexemes_read  log_unique_lexemes_read english_translation  \n",
       "113810         11.642294                 9.438113             stuffed  \n",
       "113820         11.642382                 9.438113             stuffed  \n",
       "113830         11.642470                 9.438193          They ended  \n",
       "113840         11.642558                 9.438272             tactics  \n",
       "113850         11.642646                 9.438352           dilateral  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator = Translator()\n",
    "\n",
    "k = len(el_en_trans)#checkpoint if translator crashes\n",
    "i = len(el_en_trans)#counter\n",
    "\n",
    "for el_lex in greek_lexemes[k:]:###\n",
    "    \n",
    "    #to fix a really odd bug\n",
    "    if el_lex.strip() == '':\n",
    "        \n",
    "        el_lex = ''\n",
    "        en_trans = ''\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        en_trans = translator.translate(text=el_lex, src='el', dest='en').text###\n",
    "    \n",
    "    el_en_trans[el_lex] = en_trans###\n",
    "    \n",
    "    #counter\n",
    "    if i % 100 == 0:\n",
    "        print(i, 'lexemes translated')\n",
    "    i += 1    \n",
    "\n",
    "token_counts_dfs['Greek']['english_translation'] = [el_en_trans[el_lex.strip()] for el_lex in token_counts_dfs['Greek']['most_recent_unique_lexeme']]###\n",
    "\n",
    "#save to .csv\n",
    "token_counts_dfs['Greek'].to_csv('Greek/greek_token_counts.csv', index=False)###\n",
    "\n",
    "token_counts_dfs['Greek'].tail()###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078a7a93",
   "metadata": {},
   "source": [
    "I'm never gonna use the googletrans package ever again..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
